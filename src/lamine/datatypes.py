"""Contains all types defined to represent interactions with LLM APIs. Utility parent types are defined in .utils"""

import logging
import os
from abc import ABC, abstractmethod
from dataclasses import asdict, dataclass
from importlib import import_module
from typing import Any, Optional

from dotenv import load_dotenv

from .providers import PROVIDER_IDS


@dataclass
class _Base:
    """Base class providing utility methods for other dataclasses."""

    @property
    def dict(self) -> dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict):  # type: ignore
        return cls(**data)

    @property
    def str(self) -> str:
        return ""


@dataclass
class Message(_Base):
    """
    Represents a message in a conversation.

    Attributes:
        role (str): The role of the message sender (e.g., "user", "assistant").
        content (str): The content of the message.
    """

    role: str
    content: str


@dataclass
class Answer(_Base):
    """
    Represents an answer generated by a language model.

    Attributes:
        content (str): The content of the answer.
        tokens_in (int): The number of input tokens used to generate the answer.
        tokens_out (int): The number of output tokens generated in the answer.
        source (Any): The original object returned by the API.
        time (float): The time taken to generate the answer in seconds.
    """

    content: str
    tokens_in: int
    tokens_out: int
    source: Any
    time: Optional[float] = None

    @property
    def message(self) -> Message:
        """
        Converts the answer to a Message object with the role "assistant".

        Returns:
            Message: A Message object representing the answer.
        """
        return Message("assistant", self.content)


@dataclass
class Model(_Base):
    """
    Represents a language model.

    Attributes:
        provider (str): The provider of the language model (e.g., "OpenAI", "Anthropic").
        id (str): The unique identifier of the language model.
        locations (list[str]): A list of host locations to randomly pick from.
    """

    provider: str
    id: str
    locations: Optional[list[str]] = None

    def __post_init__(self):
        """Checks whether the combination of provider, id and locations is valid."""
        # crash if provider is not supported
        self.provider = self.provider.lower()
        if self.provider not in PROVIDER_IDS:
            raise ValueError(f"Provider '{self.provider}' is not supported: {PROVIDER_IDS}.")

        # load provider for further checks
        module = import_module(f"lamine.providers.{self.provider}")
        provider = getattr(module, f"{self.provider.capitalize()}")()

        # crash if env vars are not set
        load_dotenv()
        for env_var in provider.env_vars:
            if not os.getenv(env_var):
                raise EnvironmentError(f"Provider '{self.provider}' requires environmental variable '{env_var}'")

        # warn if model_id is not supported
        if self.id not in provider.model_ids:
            logging.warning(f"Provider '{self.provider}' does not support model '{self.id}': {provider.model_ids}")

        # warn if locations are not supported
        if self.locations:
            module = import_module(f"lamine.providers.{self.provider}")
            if not provider.locations:
                logging.warning(f"Provider '{self.provider}' does not support 'locations'.")
            else:
                for location in self.locations:
                    if location not in provider.locations:
                        logging.warning(
                            f"Provider '{self.provider}' does not support location '{location}': {provider.locations}"
                        )


class Provider(ABC):
    """
    Abstract class defining the shared interface for API providers.

    Attributes:
        model_ids (Optional[list[str]]): a list of valid model ids supported by the provider, e.g. "gemini-2-flash".
        locations (Optional[list[str]]): a list of valid locations where the provider is hosts LMs, e.g. "eu-central1".
            This generally applies only to provideders Vertex, Bedrock and Azure.
        env_vars (Optional[list[str]]): a list of environmental variables (API Keys) that should exist to query the provider.
    """

    model_ids: Optional[list[str]] = None
    locations: Optional[list[str]] = None
    env_vars: Optional[list[str]] = None

    def __init__(self):
        self.model_ids = [] if not self.model_ids else self.model_ids
        self.locations = [] if not self.locations else self.locations
        self.env_vars = [] if not self.env_vars else self.env_vars

    @abstractmethod
    def get_answer(self, model: Model, conversation: list[Message], **kwargs) -> Answer:
        """
        Requests a response from a language model API for a single conversation.

        Args:
            model (Model): The language model to use for generating the response.
            conversation (list[Message]): A list of messages representing the conversation history.
            **kwargs: Additional keyword arguments like `temperature` or `top_p`.

        Returns:
            Answer: The response generated by the language model.
        """
        ...


@dataclass
class Action(_Base):
    """
    Represents an tool request by a Language Model.

    Attributes:
        name (str): The name of the tool.
        params (dict): A dictionary with input parameters.
    """

    name: str
    params: dict


@dataclass
class Observation(_Base):
    """
    Represents the result of an Action.

    Attributes:
        status (str): The status of the observation (e.g., "success", "failure").
        content (str): The content of the observation.
    """

    status: str
    content: str
