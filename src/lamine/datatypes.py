"""Contains all types defined to represent interactions with LLM APIs. Utility parent types are defined in .utils"""

import logging
import os
from dataclasses import asdict, dataclass
from importlib import import_module
from pathlib import Path
from typing import Any, Optional


@dataclass
class _Base:
    """Base class providing utility methods for other dataclasses."""

    @property
    def to_dict(self) -> dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict):
        return cls(**data)


@dataclass
class Message(_Base):
    """
    Represents a message in a conversation.

    Attributes:
        role (str): The role of the message sender (e.g., "user", "assistant").
        content (str): The content of the message.
    """

    role: str
    content: str


@dataclass
class Answer(_Base):
    """
    Represents an answer generated by a language model.

    Attributes:
        content (str): The content of the answer.
        tokens_in (int): The number of input tokens used to generate the answer.
        tokens_out (int): The number of output tokens generated in the answer.
        source (Any): The original object returned by the API.
        time (float): The time taken to generate the answer in seconds.
    """

    content: str
    tokens_in: int
    tokens_out: int
    source: Any
    time: Optional[float] = None

    @property
    def to_message(self) -> Message:
        return Message("assistant", self.content)


@dataclass
class Model(_Base):
    """
    Represents a language model.

    The combination of provider, model_id and locations is validated.

    Attributes:
        provider (str): The provider of the language model (e.g., "OpenAI", "Anthropic").
        id (str): The unique identifier of the language model.
        locations (Optional[list[str]]): A list of host locations to randomly pick from.
    """

    provider: str
    id: str
    locations: Optional[list[str]] = None

    def __post_init__(self):
        """Checks whether the combination of provider, id and locations is valid."""
        # crash if provider is not supported
        self.provider = self.provider.lower()
        dir = Path(f"{Path(__file__).parent}/providers")
        provider_ids = []
        for file in dir.iterdir():
            if file.is_file() and not file.name.startswith("_") and file.suffix == ".py":
                provider_ids.append(file.stem)

        if self.provider not in provider_ids:
            raise ValueError(f"Provider '{self.provider}' is not supported: {provider_ids}.")

        # load provider for further checks
        module = import_module(f"lamine.providers.{self.provider}")
        provider = getattr(module, f"{self.provider.capitalize()}")()

        # crash if env vars are not set
        for env_var in provider.env_vars:
            if not os.getenv(env_var):
                raise EnvironmentError(f"Provider '{self.provider}' requires environmental variable '{env_var}'")

        # warn if model_id is not supported
        if self.id not in provider.model_ids:
            logging.warning(f"Provider '{self.provider}' does not support model '{self.id}': {provider.model_ids}")

        # warn if locations are not supported, make empty list if no locations
        if self.locations:
            module = import_module(f"lamine.providers.{self.provider}")
            if not provider.locations:
                logging.warning(f"Provider '{self.provider}' does not support 'locations'.")
            else:
                for location in self.locations:
                    if location not in provider.locations:
                        logging.warning(
                            f"Provider '{self.provider}' does not support location '{location}': {provider.locations}"
                        )
        else:
            self.locations = []


@dataclass
class _Model(_Base):
    """
    Represents a LM, pointing to a single location (or non at all).

    The combination of provider / model_id and location is assumed to be pre-validated.
    This is a helper class and is not meant to be used. The corresponding modules will create
    the necessary _Model instances from a validated Model object given.

    Attributes:
        provider (str): The provider of the language model (e.g., "OpenAI", "Anthropic").
        id (str): The unique identifier of the language model.
        location (Optional[str]): A list of host locations to randomly pick from.
    """

    provider: str
    id: str
    location: Optional[str] = ""

    @property
    def to_str(self) -> str:
        if self.location:
            return f"{self.provider}:{self.id}@{self.location}"
        return f"{self.provider}:{self.id}"


@dataclass
class Action(_Base):
    """
    Represents an tool request by a Language Model.

    Attributes:
        name (str): The name of the tool.
        params (dict): A dictionary with input parameters.
    """

    name: str
    params: dict


@dataclass
class Observation(_Base):
    """
    Represents the result of an Action.

    Attributes:
        status (str): The status of the observation (e.g., "success", "failure").
        content (str): The content of the observation.
    """

    status: str
    content: str
