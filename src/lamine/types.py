"""Contains all types defined to represent interactions with LLM APIs."""

import os
from abc import ABC, abstractmethod
from dataclasses import asdict, dataclass
from importlib import import_module
from pathlib import Path
from typing import Optional

from .utils import list_to_enum


@dataclass
class Base:
    """
    Base class providing utility methods for other dataclasses.
    """
    @property
    def dict(self) -> dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict):
        return cls(**data)
    
    @property
    def str(self) -> str:
        return ""
        

@dataclass
class Message(Base):
    """
    Represents a message in a conversation.

    Attributes:
        role (str): The role of the message sender (e.g., "user", "assistant").
        content (str): The content of the message.
    """
    role: str
    content: str

@dataclass
class Answer(Base):
    """
    Represents an answer generated by a language model.

    Attributes:
        content (str): The content of the answer.
        tokens_in (int): The number of input tokens used to generate the answer.
        tokens_out (int): The number of output tokens generated in the answer.
        time (float): The time taken to generate the answer in seconds.
    """
    content: str
    tokens_in: int
    tokens_out: int
    time: Optional[float] = None

    @property
    def message(self) -> Message:
        """
        Converts the answer to a Message object with the role "assistant".

        Returns:
            Message: A Message object representing the answer.
        """
        return Message("assistant", self.content)
    
@dataclass
class Action(Base):
    """
    Represents an tool request by a Language Model.

    Attributes:
        name (str): The name of the tool.
        params (dict): A dictionary with input parameters.
    """
    name: str
    params: dict

@dataclass
class Observation(Base):
    """
    Represents the result of an Action.

    Attributes:
        status (str): The status of the observation (e.g., "success", "failure").
        content (str): The content of the observation.
    """
    status: str
    content: str

@dataclass
class Model(Base):
    """
    Represents a language model.

    Attributes:
        provider (str): The provider of the language model (e.g., "OpenAI", "Anthropic").
        id (str): The unique identifier of the language model.
        locations (list[str]): A list of host locations to randomly pick from.
    """
    provider: str
    id: str
    locations: Optional[list[str]] = None

    def __post_init__(self):
        """Checks whether the combination of provider, id and locations is valid."""
        # check if provider is supported
        self.provider = self.provider.lower()
        dir = Path(__file__).parent.resolve()
        # ToDo: make providers an Enum so user can access with `providers.`
        providers = [provider.split(".")[0] for provider in os.listdir(f"{dir}/providers") if provider.endswith(".py")]
        if self.provider not in providers:
            raise ValueError(f"Provider {self.provider} is not supported: {providers}.")
        
        # check if model_id is supported
        module = import_module(f"agilm.providers.{self.provider}")
        provider = getattr(module, f"{self.provider.capitalize()}")()
        if self.id not in provider.model_ids:
            raise ValueError(f"Provider {self.provider} does not support model {self.id}: {provider.model_ids}") # ToDo: warn instead of raise
        
        # check if locations are supported
        if self.locations:
            module = import_module(f"agilm.providers.{self.provider}")
            if not provider.locations:
                raise ValueError(f"Provider {self.provider} does not support `locations`.")
            for location in self.locations:
                if location not in provider.locations:
                    raise ValueError(f"Provider {self.provider} does not support location {location}: {provider.locations}")


class Provider(ABC):
    """Abstract class defining the shared interface for API providers."""
    model_ids: list[str]
    locations: Optional[list[str]] = None
    
    def __init__(self):
        self.model_ids = list_to_enum(self.model_ids) if self.model_ids else None
        self.locations = list_to_enum(self.locations) if self.locations else None

    @abstractmethod
    def get_answer(self, model: Model, conversation: list[Message], **kwargs) -> Answer:
        """
        Requests a response from a language model API for a single conversation.

        Args:
            model (Model): The language model to use for generating the response.
            conversation (list[Message]): A list of messages representing the conversation history.
            **kwargs: Additional keyword arguments like `temperature` or `top_p`.

        Returns:
            Answer: The response generated by the language model.
        """
        ...