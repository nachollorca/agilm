A **LA**nguage **M**odel **IN**terface **E**nginee as god intended, because the rest of the standards to inference LM APIs are :shit:.

I despise with **pasion**:
- The fact that each provider uses a different spec for LLM requests
- The OpenAI spec in particular
- LiteLLM wacky codebase

So this is how it should actually be done. You are welcome.

![Standards](assets/standards.png)

For user manual see [HOW-TO.ipynb](HOW-TO.ipynb)